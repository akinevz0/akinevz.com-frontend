networks:
  proxy:
    external: true
    name: "proxy"
  ollama:
    external: false
    name: "ollama"

name: ollama
services:
  ollama:
    container_name: "ollama"
    environment:
      - "OLLAMA_HOST=0.0.0.0:11434"
      - "OLLAMA_KEEP_ALIVE=24h"
    image: "ollama/ollama:latest"
    labels:
      traefik.enable: "true"
      traefik.http.routers.ollama.rule: "Host(`ollama.akinevz.dev`)"
      traefik.http.services.ollama.loadbalancer.server.port: 11434
    networks:
      - "proxy"
      - "ollama"
    ports:
      - "11434:11434"
    restart: "unless-stopped"
    volumes:
      - "ollama:/root/.ollama"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia

              capabilities: [gpu]

  webui:
    container_name: "webui"
    environment:
      - "OLLAMA_BASE_URL=http://host.docker.internal:11434"
      - "PORT=11444"
    image: "ghcr.io/open-webui/open-webui:main"
    labels:
      traefik.enable: "true"
      traefik.http.routers.webui.rule: "Host(`webui.akinevz.dev`)"
      traefik.http.services.webui.loadbalancer.server.port: 11444
    networks:
      - "proxy"
      - "ollama"
    ports:
      - "11444:11444"
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: "unless-stopped"
    volumes:
      - "/ollama-webui:/app/backend/data"

volumes:
  ollama:
    external: true
